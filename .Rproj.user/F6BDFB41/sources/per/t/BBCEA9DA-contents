---
title: "Trial design model"
format: html
editor: source
echo: false
warning: false
message: false
---

## Summary

We will construct a design stage model to predict attrition rates based on trial design features while accounting for differences in trial duration. We will construct the initial model using aggregate-level data for non-experimental arms (i.e. placebo, active comparator) to facilitate generalisability across trials of different index conditions. The model will be similar to that described in NICE Technical Support Document 3 (3.2. Rate data: Binomial likelihood and cloglog link) for modelling rates where event times are not available.

## Data

```{r makedata}
library(tidyverse)

df <- tibble(
  trial_id = c(1, 1, 2, 2),
  r = c(25, 31, 73, 91),
  N = c(100, 101, 203, 204),
  dur = c(0.5, 0.5, 0.25, 0.25),
  arm_type = c("Placebo", "Active", "Active", "Placebo"),
  double_blind = c(1, 1, 0, 0),
  triple_blind = c(0, 0, 1, 1),
  other_covariates = c("...", "...", "...", "...")
)

df %>% knitr::kable()
```

-   r - Attrition event count
-   N - Number of participants in arm
-   dur - Trial duration in years

All covariates will be dummy coded, with levels within categorical groupings (e.g. blinding) one-hot encoded.

We will include the following covariates (1 = yes, 0 = no):

-   Sample size (\<250, \>=250-\<500, \>=500-\<750, \>=750-\<1000, \>=1000)
-   Arm size (\<100, \>=100-\<200, \>=200-\<300, \>=300)
-   Treatment arm type (placebo - 1, active comparator - 0)
-   Trial duration (\<6m, \>=6m-\<1yr, \>=1yr)
-   Number of arms (2, 3, 4, \>4)
-   Phase (3, 4)
-   Blinding (double, triple, quadruple, open-label)
-   Number of facilities (\<100, \>=100-\<200, \>=200)
-   Number of primary outcomes (1, 2, 3, \>3)
-   WHO regions involved (Europe, Americas, WPac, SEA, African, EMed)

## Model description

### Likelihood

For arm $j$ in trial $i$, we will specify the model likelihood using the binomial distribution:

\begin{aligned}
r_{ij} \sim \text{Binomial}(N_{ij}, \theta_{ij}) \\
\end{aligned}

Where $r$ indicates the observed number of attrition events, $N$ indicates the number of participants and $\theta$ indicates the probability of attrition at person-time $t$.

Informed by findings from our previous IPD analysis of attrition rates, we will model $\theta_{ij}$ as a function of the Gompertz Cumulative Distribution Function (CDF):

\begin{aligned}
F(t_{ij}) &= 1 - \exp \left(-\frac{b_{ij}}{a_{ij}} \exp(a_{ij} t_{ij}) \right),
\end{aligned}

where $a \geq 0$ is the shape parameter and $b \geq 0$ is the rate parameter, with both parameters constrained to be positive.

We initially explored placing covariates on both $a$ and $b$, but this specification resulted in convergence issues and model instability. Therefore, we will allow $a$ to vary by arm-trial combination without adjustment and place covariates on $b$ with a random intercept:

\begin{aligned}
b_{ij} = \exp(\beta_{0ij} + \beta_{1ij}X_{1ij} + \dots + \beta_{kij}X_{kij}),
\end{aligned}

where $\beta_{0ij}$ is a random intercept representing the baseline log-hazard for arm $j$ in trial $i$, $X_{1ij} \dots X_{kij}$ are the covariates and $\beta_{1ij} \dots \beta_{kij}$ are the corresponding regression coefficients.

### Shrinkage and regularisation

To reduce the risk of overfitting and improve the interpretability of covariate effects, we will apply shrinkage to the regression coefficients on $b$, parameterising as:

\begin{aligned}
\beta_k = z_k \cdot \tau \cdot \lambda_k
\end{aligned}

where $z_k$ is a latent standard normal variable, $\tau$ is a shrinkage factor applied to all coefficients (i.e. global) and $\lambda_k$ is a covariate-specific (i.e. local) shrinkage factor.

This approach is similar to the Horseshoe prior, allowing most covariates to be shrunk towards zero while a small number of coefficients with strong signals "escape" shrinkage. This approach assumes that only a subset of covariates will have any meaningful effects, which we believe is feasible given the moderate number of covariates we will include.

As our primary interest is the effect of trial design features on attrition at the arm-level (placebo and active comparator), we will exclude treatment arm type from shrinkage and assign it a separate weakly informative prior.

### Priors

To promote model stability, we will specify weakly informative priors for $\alpha_{ij}$, $\beta_{0ij}$ and $\beta arm_{ij}$:

\begin{aligned}
\alpha_{ij}, \beta_{0ij}, \beta arm_{ij} &\sim \text{Normal}(0, 1).
\end{aligned}

For shrinkage parameters, we will specify a weakly informative prior for $z_k$ and a half-Student-$t$ for local and global shrinkage:

\begin{aligned}
z_k &\sim \text{Normal}(0, 1) \\
\tau, \lambda_k &\sim t^+(3, 0, 1) \\
\end{aligned}

The heavily-tailed half-student-$t$ will encourage weaker coefficients to be shrunk towards zero.

## Model code

``` stan
data {
  int<lower=0> I; // Number of trials
  int<lower=0> K; // Number of covariates
  int<lower=0> r[I]; // Observed attrition events per trial
  int<lower=0> N[I]; // Number of participants per trial
  vector[I] dt; // Time in years
  vector[I] arm; // Treatment arm (1 = placebo, 0 = active)
  matrix[I, K] X; // Covariates
}

parameters {
  real mu1_mean; // Global baseline log-hazard
  vector[I] mu1_raw; // Raw baseline log-hazard
  real<lower=0> sigma_mu1; // Baseline log-hazard variation
  
  real a_mean; // Global shape parameter
  vector[I] a_raw; // Raw shape parameter
  real<lower=0> sigma_a; // Shape variation
  
  real beta_arm;
  vector[K] z;
  real<lower=0> tau; // Global shrinkage factor
  vector<lower=0>[K] lambda; // Local shrinkage factor
}

transformed parameters {
  vector[I] mu1 = mu1_mean + mu1_raw * sigma_mu1; // Trial-specific baseline log-hazard
  vector[I] a = a_mean + a_raw * sigma_a; // Trial-specific shape
  vector[K] beta = z .* tau .* lambda; // Coefficient with shrinkage factors applied
  
  vector[I] b;
  vector[I] p;

  for (i in 1:I) {
    b[i] = exp(mu1[i] + arm[i] * beta_arm + dot_product(X[i], beta)); // Rate
    real exponent = a[i] * dt[i];
    real time_part = (fabs(a[i]) < 1e-6) ? dt[i] : expm1(exponent) / a[i];
    p[i] = 1 - exp(-b[i] * time_part); // Gompertz CDF
  }
}

model {
  mu1_mean ~ normal(0, 1);
  mu1_raw ~ normal(0, 1);
  sigma_mu1 ~ normal(0, 1);
  
  a_mean ~ normal(0, 1);
  a_raw ~ normal(0, 1);
  sigma_a ~ normal(0, 1);
  
  beta_arm ~ normal(0, 1);
  z ~ normal(0, 1);
  lambda ~ normal(0, 1); // Local scale
  tau ~ normal(0, 1); // Global scale

  r ~ binomial(N, p);
}

generated quantities {
  vector[I] r_new;
  vector[I] p_new;
  vector[I] rate = exp(mu1); // Baseline hazard  
  real mean_rate = mean(rate); // Summary of baseline hazard (Mean, SD)
  real sd_rate = sd(rate);
  
  real shrinkage_effective_params = sum(lambda ./ sqrt(1 + lambda.^2));

  for (i in 1:I) {
    real exponent = a[i] * dt[i];
    real time_part = (fabs(a[i]) < 1e-6) // Safely approximate a if close to 0
      ? dt[i] // Reduce to exponential if 0
      : expm1(exponent) / a[i]; // Otherwise use full expression
    p_new[i] = 1 - exp(-b[i] * time_part);
    r_new[i] = binomial_rng(N[i], p_new[i]);
  }
}
```

## Model performance and predictions

The following section demonstrates the results of fitting the model specified in the previous section and plans for predictive applications.

### Diagnostics and posterior predictive checks

Summary of rhat values for main parameters (a, b, coefficients, intercept, rate)

```{r rhat_sum}
imp_df <- read_csv("../outputs/rhat_sum_protocol.csv") %>% 
  rename(
    median = med_rhat,
    min = min_rhat,
    max = max_rhat
  )

imp_df %>% knitr::kable()
```

Comparing observed and predicted attrition count distributions

```{r ppc plot}
knitr::include_graphics("ppc.jpg")
```

### Predictions

We can use model estimates to make predictions about attrition rates based on trial design features.

For example, we will take a trial with the following features:

-   250 participants receiving placebo, 89 do not complete the trial
-   Trial is 26 weeks (0.5 years) long
-   Parallel-design (experimental vs placebo), phase 3 trial
-   Sample size of 500 (250 per arm)
-   Double-blinding, conducted across 80 facilities in European region
-   Had a single primary outcome (e.g. change in HbA1c)

Beta values for each covariate with shrinkage applied are:

```{r betas}
betas <- readRDS("../outputs/betas_covs.rds") %>% select(cov_name, beta = mean)
betas %>% knitr::kable()
```

We will take the mean $a$ (-2.18) and baseline log-hazard rate (-0.784) across all trials for this example. 

$b$ can be calculated as:

\begin{aligned}
b_{ij} = \exp(-0.784 + 1 \cdot -0.1758 + 1 \cdot 0.0299 + 1 \cdot 0.0203 \\
+ 1 \cdot 0.1224 + 1 \cdot -0.0102 + 1 \cdot -0.2986 + 1 \cdot -0.0209 \\
+ 1 \cdot 0.0029 + 1 \cdot -0.0081 + 1 \cdot -0.2471), \\
b_{ij} = 0.1746
\end{aligned}

Using $a$ and $b$, we can then estimate the hazard rate and cumulative hazard over time:

```{r makedata2}
library(flexsurv)

df2 <- tibble(
  time = c(0, 0.1, 0.2, 0.3, 0.4, 0.5),
  a = rep(-1.652, 6),
  b = rep(exp(-2.18), 6),
)

df2_haz <- df2 %>% 
  mutate(
    haz = pmap_dbl(
      list(time, a, b),
      ~ hgompertz(x = ..1, shape = ..2, rate = ..3)
    ),
    chaz = pmap_dbl(
      list(time, a, b),
      ~ Hgompertz(x = ..1, shape = ..2, rate = ..3)
    )
  )

plot <- df2_haz %>% 
  ggplot(aes(x = time, y = haz)) +
  geom_line() +
  scale_x_continuous(n.breaks = 6) +
  theme_bw() +
  labs(x = "Trial duration in weeks", y = "Hazard rate")

print(plot)

plot2 <- df2_haz %>% 
  ggplot(aes(x = time, y = chaz)) +
  geom_line() +
  scale_x_continuous(n.breaks = 6) +
  theme_bw() +
  labs(x = "Trial duration in weeks", y = "Cumulative hazard")

print(plot2)
```

### Prediction with uncertainty

To gauge the uncertainty of predictions, we can sample posterior point estimates using Monte Carlo simulation. To do this, we will sample from a multivariate normal distribution using the coefficients and variance-covariance matrices obtained from the design-stage model posterior draws. We will draw samples using the *mvrnorm* package.

``` r
n <- 100
mu <- matrix(c(rnorm(100, mean = 0.221, sd = 1), rnorm(100, mean = -1.77, sd = 1)), ncol = 2)
colnames(mu) <- c("rate", "shape")
sigma <- matrix(c(0.0289, -0.0004, -0.0004, 0.0561), ncol = 2)
colnames(sigma) <- c("shape", "rate")
rownames(sigma) <- c("shape", "rate")
samples <- mvrnorm(n = n, mu = mu, sigma = sigma)
```
